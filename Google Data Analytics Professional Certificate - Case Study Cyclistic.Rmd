---
title: "Google Data Analytics Professional Certificate-Cyclistic Case Study"
author: "Menekse Ayhan"
date: "2024-07-29"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}

install.packages("tidyverse")
library(tidyverse)
library(ggplot2)
library(dplyr)

```

## Including Plots

## Overview
This report is a part of the "[Google Data Analytics Professional Certificate's](https://www.coursera.org/professional-certificates/google-data-analytics?utm_source=gg&utm_medium=sem&utm_campaign=15-GoogleDataAnalytics-ROW&utm_content=15-GoogleDataAnalytics-ROW&campaignid=12566515400&adgroupid=117869292685&device=c&keyword=google%20data%20analytics%20professional%20certificate&matchtype=p&network=g&devicemodel=&adpostion=&creativeid=507290840624&hide_mobile_promo&gclid=Cj0KCQjwlOmLBhCHARIsAGiJg7nCDJoKyJBvSNg_ZxabdVBTbqVrKCXJUKI_nAEzpv0AmrXkmcYWZ9kaAqIPEALw_wcB)" capstone project offered by [Coursera](https://www.coursera.org/). 

In this report, the chosen case study is the first problem in track#1, also known as '**Cyclistic**,' an imaginary bike-sharing company in Chicago. The company offers both traditional and assistive bikes to both casual riders and riders who are annual members.

### The quoted scenario provided by the course:
"You are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the companyâ€™s future success depends on maximizing the number of annual memberships. Therefore, your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve your recommendations, so they must be backed up with compelling data insights and professional data visualizations."

## "Ask" 
The questions that the stakeholders want answer in this scenario are:

1. How do annual members and casual riders use Cyclistic bikes differently?
2. Why would casual riders buy Cyclistic annual memberships?
3. How can Cyclistic use digital media to influence casual riders to become members? 

From these questions, the priority-1 task in this project is to identify the differences of bike usage between annual members and casual riders. Then, use those differences to figure out how to keep the existing and attract new annual members to maximize Cyclistic's profit.

## "Prepare"

__Note__: All the data preparation processes and tools involved were all under **Windows 10 (Home)** operating system.

The [**data**](https://divvy-tripdata.s3.amazonaws.com/index.html) used in this scenario was provided by the course under this [**license**](https://www.divvybikes.com/data-license-agreement). There were 12 data files for the data collected in the last 12 months. Each file was originally compressed in a .zip file format. The .zip files were named according to the month in the year the data was collected. For example, the file containing the data from **JULY 2023** was named "**202307-divvy-tripdata.zip**." 

From the data provided, the latest data was from **JULY 2023**, and the oldest **JUNE 2024**. 


## "Process"
The tools used in this project are **RStudio** (2021.09.0 Build 351) runs on **R** (version 4.1.1) and **Microsoft Excel** (Office 365 version), all, as stated above, run under Windows 10 (Home) operating system.

R was chosen because it can manage large data sets much quicker than spreadsheets. It can also visualize and create well-formatted reports, complete with code chunks and pictures. Excel, in this case, is for creating a temporary summary tables and visualizations which were later ported into RStudio to create this report.

### Importing data into RStudio
Before importing any data into RStudio, the working directory must be changed to match the directory in which the data is stored. The quickest way to do this is to use Windows' GUI to navigate to the folder containing those files, then copy path string from the address bar, for example, "__C:\\Users\\...\\Cyclistic_data__", then paste the copied path string in the function '**setwd()**' but change all the **backslash** (__\\__) into **slash** (__/__) to comply with R syntax:

getwd()
setwd("C:/Users/.../Cyclistic_data--Example file location")

```{r, echo=FALSE}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Next, use the "**read_csv()**" function to import data from each .csv file and store in R's data objects as data frames. In this case, each data frame was given its corresponding name according to the data stored in each file. For example, the data collected from **JULY 2023** will be stored in a data frame named "**JUL23**." 

The following code chunk shows the data import step:

```{r}

JUL23 <- read_csv("202307-divvy-tripdata.csv")

```

The data in the rest of the downloaded files was imported with the above code and stored in data frames named **AUG23, SEP23,...,JUN24**, totaling to 12 objects in R's environment. 

## DATA CLEANING

## Data Integrity Checkups, Handling NAs, Check for Duplicated Rows

```{r}
colnames(JUL23)
glimpse(JUL23)
summary(JUL23)
colSums(is.na(JUL23))
JUL23 %>% 
  group_by(ride_id) %>% 
  filter(n()>1)

```

The data in the rest of the downloaded files was checked with the above code and stored in data frames named **AUG23, SEP23,...,JUN24**, totaling to 12 objects in R's environment. 

##Inspecting and comparing data type in each column of every data frame
```{r}
dtJUL23 <- sapply(JUL23,typeof)
dtAUG23 <- sapply(AUG23,typeof)
dtSEP23 <- sapply(SEP23,typeof)
dtOCT23 <- sapply(OCT23,typeof)
dtNOV23 <- sapply(NOV23,typeof)
dtDEC23 <- sapply(DEC23,typeof)
dtJAN24 <- sapply(JAN24,typeof)
dtFEB24 <- sapply(FEB24,typeof)
dtMAR24 <- sapply(MAR24,typeof)
dtAPR24 <- sapply(APR24,typeof)
dtMAY24 <- sapply(MAY24,typeof)
dtJUN24 <- sapply(JUN24,typeof)

identical(dtJUL23,dtAUG23)
identical(dtAUG23,dtSEP23)
identical(dtSEP23,dtOCT23)
identical(dtOCT23,dtNOV23)
identical(dtNOV23,dtDEC23)
identical(dtDEC23,dtJAN24)
identical(dtJAN24,dtFEB24)
identical(dtFEB24,dtMAR24)
identical(dtMAR24,dtAPR24)
identical(dtAPR24,dtMAY24)
identical(dtMAY24,dtJUN24)
```

## Combining All Data Frames

At this point, the data integrity was checked and confirmed its consistency. There was nothing to add or remove from the data frames just yet. They were ready to be combined into one big data frame with complete information ready for the analysis.

The following code combined all data frame together into a single big data frame named "**combined_data**":

Summarise combined data:
```{r}
combined_data <- bind_rows(JUL23,AUG23,SEP23,OCT23,NOV23,DEC23,JAN24,FEB24,MAR24,APR24,MAY24,JUN24)

View(combined_data)
colnames(combined_data)
nrow(combined_data)
dim(combined_data)
head(combined_data)
glimpse(combined_data)
str(combined_data)
summary(combined_data)
colSums(is.na(combined_data))

```

# There are a few problems we will need to fix:
# (1) We will want to add a calculated field for length of ride since the 2023-2024 data did not have the "tripduration" column. We will add "ride_length" to the entire dataframe for consistency.

# (2) The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.



```{r}
combined_data$ride_length <- difftime(combined_data$ended_at,combined_data$started_at)

summary(combined_data$ride_length)

```
Check to make sure the proper number of observations were reassigned
```{r}
table(combined_data$rideable_type)
table(combined_data$member_casual)
```
Convert data type of "numeric",
```{r}
is.factor(combined_data$ride_length)
combined_data$ride_length <- as.numeric(as.character(combined_data$ride_length))
is.numeric(combined_data$ride_length)

summary(combined_data$ride_length)
```
# Add columns that list the date, month, day, and year of each ride

# This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level

```{r}

combined_data$date <- as.Date(combined_data$started_at)
combined_data$receive_month <- format(as.Date(combined_data$date), "%m")
combined_data$day <- format(as.Date(combined_data$date), "%d")
combined_data$year <- format(as.Date(combined_data$date), "%Y")
combined_data$day_of_week <- format(as.Date(combined_data$date), "%A")
table(combined_data$day_of_week)
str(combined_data)

```
# Remove "bad" data

# The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality ride_length was negative

# We will create a new version of the dataframe (v1) since data is being removed
```{r}
combined_data_v1 <- combined_data[!(combined_data$ride_length <= 0),]
str(combined_data_v1)
glimpse(combined_data_v1)
```
# Create a csv file that we will visualize in Excel, Tableau, or my presentation software
```{r}
write.csv(combined_data_v1, file = 'combined_data_v1.csv')
```

##CONDUCT DESCRIPTIVE ANALYSIS

```{r}
mean(combined_data_v1$ride_length) 
median(combined_data_v1$ride_length) 
max(combined_data_v1$ride_length) 
min(combined_data_v1$ride_length) 

summary(combined_data_v1$ride_length)
```
# Compare members and casual users
```{r}
aggregate(combined_data_v1$ride_length ~ combined_data_v1$member_casual, FUN = mean)
aggregate(combined_data_v1$ride_length ~ combined_data_v1$member_casual, FUN = median)
aggregate(combined_data_v1$ride_length ~ combined_data_v1$member_casual, FUN = max)
aggregate(combined_data_v1$ride_length ~ combined_data_v1$member_casual, FUN = min)

```

# See the average ride time by each day for members vs casual users
```{r}
aggregate(combined_data_v1$ride_length ~ combined_data_v1$member_casual + 
            combined_data_v1$day_of_week, FUN = mean)
```
# Notice that the days of the week are out of order. Let's fix that.
```{r}
combined_data_v1$day_of_week <- ordered(combined_data_v1$day_of_week, 
levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", 
         "Saturday"))
```
# Now, let's run the average ride time by each day for members vs casual users
```{r}
aggregate(combined_data_v1$ride_length ~ combined_data_v1$member_casual + 
            combined_data_v1$year, FUN = mean)

```
#analyze ridership data by type and weekday
```{r}
combined_data_v1 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday) 
```
##visualization

Let's visualize the percentage of members

```{r}
data1 <- combined_data_v1 %>% 
  group_by(member_casual) %>% 
  summarise(number_of_rides=n(),
            Percentage= (number_of_rides/5732648)*100)

ggplot(data1, aes(x="", y=Percentage, fill=member_casual)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(title="Total %", caption="Data From JUL 2023 - JUN 2024",fill="Membership Status:" )+
  geom_text(aes(label = round(Percentage,2)),position=position_stack(vjust=0.5),
            color = "black", size=6) +
  scale_fill_manual(values = c("coral1", "cyan3"))+
  theme_void() + 
  theme(plot.title=element_text(hjust=0.5, size=22),
legend.justifician=c("right", "top"),
legend.title=element_text(size=10),
legend.text=element_text(size=10),
legend.key.height=unit(0.3, 'cm'),
legend.key.width=unit(0.3, 'cm'),
plot.caption=element_text(size=10))
```
Let's visualize the number of rides by rider type and month

```{r}
combined_data_v1 %>% 
  mutate(started_month = month(started_at, label = TRUE)) %>% 
  group_by(member_casual, started_month) %>% 
  summarise(number_of_rides = n(),
            ,average_duration = mean(ride_length)) %>% 
  ggplot(aes(x = started_month, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title="Number of Monthly Bikes by Members",
       fill="Membership Status:", x="Month", y="Number of Rides")
```
Let's visualize the number of rides by rider type and days
```{r}
combined_data_v1 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title="Number of Weekly Bikes by Members",
       fill="Membership Status:", x="Month", y="Number of Rides")
```

Let's visualize the average duration lenght by rider type and month
```{r}
combined_data_v1 %>% 
  mutate(started_month = month(started_at, label = TRUE)) %>% 
  group_by(member_casual, started_month) %>% 
  summarise(number_of_rides = n(),
            ,average_duration = mean(ride_length)) %>% 
  ggplot(aes(x = started_month, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")+
    labs(title="Average Ride Lenght by Members",
       fill="Membership Status:", x="Month", y="Average Ride Lenght")
```
Let's visualize the average duration lenght by rider type and days
```{r}
combined_data_v1 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title="Average Ride Lenght by Members",
       fill="Membership Status:", x="Month", y="Average Ride Lenght")
```

Let's visualize the number of rides by bike type
```{r}
combined_data_v1 %>% 
  group_by(member_casual, rideable_type) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, rideable_type)  %>% 
  ggplot(aes(x = rideable_type, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title="Number of Rides of Different Bike Types",caption="Data From JUL 2023 - JUN 2024",
       fill="Membership Status:", x="Rideable Type", y="Number of Rides")
```
Let's visualize the number of rides by bike type and weekend-weekday
```{r}
combined_data_v1 %>% 
mutate(weekend = ifelse(wday(started_at) %in% c(1,7), "weekend", "weekday")) %>% 
  group_by(member_casual, weekend) %>% 
  summarise(number_of_rides = n()
            ,average_duration = sum(ride_length)) %>% 
  arrange(member_casual, weekend)  %>% 
  ggplot(aes(x = weekend, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")+
  labs(title="Average of Ride Lenght Week",caption="Data From JUL 2023 - JUN 2024",
       fill="Membership Status:", x="Week", y="Average Ride Lenght")
```






